import streamlit as st
import pandas as pd
import os
import smtplib
import time
import io
import traceback
import threading
import uuid
import re
import sqlite3
import json
import random
import concurrent.futures
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, date, timedelta
from datetime import timezone
import pytz
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
from streamlit.runtime.scriptrunner import add_script_run_ctx

# --- 1. ç¶²é è¨­å®š ---
st.set_page_config(page_title="æŠ„è¥²æ˜¯ä¸å°çš„è¡Œç‚º", layout="wide", page_icon="â˜˜ï¸")

# --- 2. æ•æ‰å…¨åŸŸéŒ¯èª¤ ---
try:
    # ==========================================
    # 0. åŸºç¤è¨­å®šèˆ‡æ™‚å€
    # ==========================================
    TW_TZ = pytz.timezone('Asia/Taipei')

    MAX_IMAGE_BYTES = 10 * 1024 * 1024  # å–®æª”åœ–ç‰‡ 10MB ä¸Šé™
    QUEUE_DB_PATH = "task_queue_v4_wal.db"
    
    # Google Sheet ç¶²å€
    SHEET_URL = "https://docs.google.com/spreadsheets/d/108HJ47lwEzHrJ7I0-olC3S-oMZBIF60-55fQClqjIBw/edit"
    
    SHEET_TABS = {
        "main": "main_data", 
        "settings": "settings",
        "roster": "roster",
        "inspectors": "inspectors",
        "duty": "duty",
        "teachers": "teachers",
        "appeals": "appeals"
    }

    EXPECTED_COLUMNS = [
        "æ—¥æœŸ", "é€±æ¬¡", "ç­ç´š", "è©•åˆ†é …ç›®", "æª¢æŸ¥äººå“¡",
        "å…§æƒåŸå§‹åˆ†", "å¤–æƒåŸå§‹åˆ†", "åƒåœ¾åŸå§‹åˆ†", "åƒåœ¾å…§æƒåŸå§‹åˆ†", "åƒåœ¾å¤–æƒåŸå§‹åˆ†", "æ™¨é–“æ‰“æƒåŸå§‹åˆ†", "æ‰‹æ©Ÿäººæ•¸",
        "å‚™è¨»", "é•è¦ç´°é …", "ç…§ç‰‡è·¯å¾‘", "ç™»éŒ„æ™‚é–“", "ä¿®æ­£", "æ™¨æƒæœªåˆ°è€…", "ç´€éŒ„ID"
    ]

    APPEAL_COLUMNS = [
        "ç”³è¨´æ—¥æœŸ", "ç­ç´š", "é•è¦æ—¥æœŸ", "é•è¦é …ç›®", "åŸå§‹æ‰£åˆ†", "ç”³è¨´ç†ç”±", "ä½è­‰ç…§ç‰‡", "è™•ç†ç‹€æ…‹", "ç™»éŒ„æ™‚é–“", "å°æ‡‰ç´€éŒ„ID"
    ]

    # ==========================================
    # 1. Google é€£ç·šæ•´åˆ
    # ==========================================

    @st.cache_resource
    def get_credentials():
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        if "gcp_service_account" not in st.secrets:
            st.error("âŒ æ‰¾ä¸åˆ° secrets è¨­å®š")
            return None
        creds_dict = dict(st.secrets["gcp_service_account"])
        return ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)

    @st.cache_resource
    def get_gspread_client():
        try:
            creds = get_credentials()
            if not creds: return None
            return gspread.authorize(creds)
        except Exception as e:
            st.error(f"âŒ Google Sheet é€£ç·šå¤±æ•—: {e}")
            return None

    @st.cache_resource
    def get_drive_service():
        try:
            creds = get_credentials()
            if not creds: return None
            return build('drive', 'v3', credentials=creds, cache_discovery=False)
        except Exception as e:
            st.warning(f"âš ï¸ Google Drive é€£ç·šå¤±æ•—: {e}")
            return None

    @st.cache_resource(ttl=21600)
    def get_spreadsheet_object():
        client = get_gspread_client()
        if not client: return None
        try: return client.open_by_url(SHEET_URL)
        except Exception as e: st.error(f"âŒ ç„¡æ³•é–‹å•Ÿè©¦ç®—è¡¨: {e}")
        return None

    def get_worksheet(tab_name):
        max_retries = 3
        wait_time = 2
        sheet = get_spreadsheet_object()
        if not sheet: return None
        for attempt in range(max_retries):
            try:
                try: return sheet.worksheet(tab_name)
                except gspread.WorksheetNotFound:
                    cols = 20 if tab_name != "appeals" else 15
                    ws = sheet.add_worksheet(title=tab_name, rows=100, cols=cols)
                    if tab_name == "appeals": ws.append_row(APPEAL_COLUMNS)
                    return ws
            except Exception as e:
                if "429" in str(e): 
                    time.sleep(wait_time * (attempt + 1))
                    continue
                else: 
                    print(f"âŒ è®€å–åˆ†é  '{tab_name}' å¤±æ•—: {e}")
                    return None
        return None

    def upload_image_to_drive(file_obj, filename):
        def _upload_action():
            service = get_drive_service()
            if not service: raise Exception("Drive Service Init Failed")
            
            folder_id = st.secrets["system_config"].get("drive_folder_id")
            if not folder_id: raise Exception("No Drive Folder ID")

            file_metadata = {'name': filename, 'parents': [folder_id]}
            media = MediaIoBaseUpload(file_obj, mimetype='image/jpeg')
            
            file = service.files().create(
                body=file_metadata, media_body=media, fields='id', supportsAllDrives=True
            ).execute(num_retries=1)
            
            try:
                service.permissions().create(fileId=file.get('id'), body={'role': 'reader', 'type': 'anyone'}).execute()
            except: pass 
            return f"https://drive.google.com/thumbnail?id={file.get('id')}&sz=w1000"

        try:
            return execute_with_retry(_upload_action)
        except Exception as e:
            print(f"âš ï¸ Drive ä¸Šå‚³æœ€çµ‚å¤±æ•—: {str(e)}")
            return None

    def clean_id(val):
        try:
            if pd.isna(val) or val == "": return ""
            return str(int(float(val))).strip()
        except: return str(val).strip()

    # ==========================================
    # åœ–ç‰‡æš«å­˜è³‡æ–™å¤¾
    # ==========================================
    IMG_DIR = "evidence_photos"
    os.makedirs(IMG_DIR, exist_ok=True)
"""
    # ==========================================
    # SQLite èƒŒæ™¯ä½‡åˆ—ç³»çµ± (SRE Hardened + ThreadPool)
    # ==========================================
    _queue_lock = threading.Lock()

    @st.cache_resource
    def get_queue_connection():
        conn = sqlite3.connect(
            QUEUE_DB_PATH, 
            check_same_thread=False, 
            timeout=30.0, 
            isolation_level="IMMEDIATE" 
        )
        
        try:
            conn.execute("PRAGMA journal_mode=WAL;")
            conn.execute("PRAGMA busy_timeout=30000;")
            conn.execute("PRAGMA synchronous=NORMAL;")
        except:
            pass

        conn.execute("CREATE INDEX IF NOT EXISTS idx_status_created ON task_queue (status, created_ts);")
        conn.commit()
        return conn

    def enqueue_task(task_type: str, payload: dict) -> str:
        conn = get_queue_connection()
        task_id = str(uuid.uuid4())
        created_ts = datetime.now(timezone.utc).isoformat()
        payload_json = json.dumps(payload, ensure_ascii=False)

        with _queue_lock:
            conn.execute(
                "INSERT INTO task_queue (id, task_type, created_ts, payload_json, status, attempts, last_error) "
                "VALUES (?, ?, ?, ?, 'PENDING', 0, NULL)",
                (task_id, task_type, created_ts, payload_json)
            )
            conn.commit()
        return task_id

    def get_queue_metrics():
        conn = get_queue_connection()
        metrics = {"pending": 0, "retry": 0, "failed": 0, "oldest_pending_sec": 0, "recent_errors": []}
        with _queue_lock:
            cur = conn.cursor()
            cur.execute("SELECT status, COUNT(*) FROM task_queue GROUP BY status")
            rows = cur.fetchall()
            for status, count in rows:
                if status == 'PENDING': metrics["pending"] = count
                elif status == 'RETRY': metrics["retry"] = count
                elif status == 'FAILED': metrics["failed"] = count
            
            cur.execute("SELECT MIN(created_ts) FROM task_queue WHERE status IN ('PENDING', 'RETRY')")
            oldest_ts_str = cur.fetchone()[0]
            
            cur.execute("SELECT last_error, created_ts FROM task_queue WHERE status='FAILED' OR status='RETRY' ORDER BY created_ts DESC LIMIT 5")
            metrics["recent_errors"] = cur.fetchall()

        if oldest_ts_str:
            try:
                created = datetime.fromisoformat(oldest_ts_str.replace("Z", "+00:00"))
                now = datetime.now(pytz.utc)
                metrics["oldest_pending_sec"] = (now - created).total_seconds()
            except: pass
        return metrics

    def fetch_next_task(max_attempts: int = 6):
        conn = get_queue_connection()
        with _queue_lock:
            try:
                cur = conn.cursor()
                cur.execute(
                    """
                    SELECT id, task_type, created_ts, payload_json, status, attempts, last_error
                    FROM task_queue
                    WHERE status IN ('PENDING', 'RETRY')
                    AND attempts < ?
                    ORDER BY created_ts ASC
                    LIMIT 1
                    """,
                    (max_attempts,)
                )
                row = cur.fetchone()
                
                if not row:
                    conn.commit()
                    return None

                task_id, task_type, created_ts, payload_json, status, attempts, last_error = row
                
                cur.execute(
                    "UPDATE task_queue SET status = 'IN_PROGRESS', attempts = attempts + 1 WHERE id = ? AND status = ?",
                    (task_id, status)
                )
                
                if cur.rowcount == 0:
                    conn.commit()
                    return None

                conn.commit()
                
                try: payload = json.loads(payload_json)
                except: payload = {}
                    
                return {
                    "id": task_id,
                    "task_type": task_type,
                    "created_ts": created_ts,
                    "payload": payload,
                    "status": "IN_PROGRESS",
                    "attempts": attempts + 1,
                    "last_error": last_error,
                }
            except Exception as e:
                try: conn.rollback()
                except: pass
                return None

    def update_task_status(task_id: str, status: str, attempts: int, last_error: str | None):
        conn = get_queue_connection()
        with _queue_lock:
            conn.execute(
                "UPDATE task_queue SET status = ?, attempts = ?, last_error = ? WHERE id = ?",
                (status, attempts, last_error, task_id),
            )
            conn.commit()
    
    def requeue_stuck_tasks(stale_seconds=600):
        # ç°¡å–®å¯¦ä½œï¼šç›®å‰ç­–ç•¥ä¾è³´é‡è©¦èˆ‡ attempts é™åˆ¶
        pass 

    def _exp_backoff_seconds(attempts: int) -> float:
        base = 2.0
        cap = 60.0
        return random.uniform(1.0, min(cap, base * (2 ** max(0, attempts))))
"""

    # ==========================================
    # 3. ä¸»ç¨‹å¼ä»‹é¢
    # ==========================================
    SYSTEM_CONFIG = load_settings()
    ROSTER_DICT = load_roster_dict()
    INSPECTOR_LIST = load_inspector_list()
    TEACHER_MAILS = load_teacher_emails()
    
    all_classes, structured_classes = load_sorted_classes()
    if not all_classes:
        all_classes = ["æ¸¬è©¦ç­ç´š"]
        structured_classes = [{"grade": "å…¶ä»–", "name": "æ¸¬è©¦ç­ç´š"}]

    grades = sorted(list(set([c["grade"] for c in structured_classes])))

    def get_week_num(d):
        try:
            start = datetime.strptime(SYSTEM_CONFIG["semester_start"], "%Y-%m-%d").date()
            if isinstance(d, datetime): d = d.date()
            return max(0, ((d - start).days // 7) + 1)
        except: return 0

    now_tw = datetime.now(TW_TZ)
    today_tw = now_tw.date()

    st.sidebar.title("ğŸ« åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["ç³¾å¯Ÿåº•å®¶ğŸ‘€", "ç­ç´šè² è²¬äººğŸ¥¸", "çµ„é•·ã„‰çª©ğŸ’ƒ"])

    with st.sidebar.expander("ğŸ”§ ç³»çµ±é€£ç·šè¨ºæ–·", expanded=False):
        if get_gspread_client(): 
            st.success("âœ… Google Sheets é€£ç·šæ­£å¸¸")
        else: 
            st.error("âŒ Sheets é€£ç·šå¤±æ•—")
            
        if "gcp_service_account" in st.secrets: 
            st.success("âœ… GCP æ†‘è­‰å·²è®€å–")
        else: 
            st.error("âš ï¸ æœªè¨­å®š GCP Service Account")
            
        if "system_config" in st.secrets and "drive_folder_id" in st.secrets["system_config"]:
            st.success("âœ… Drive è³‡æ–™å¤¾ ID å·²è¨­å®š")
        else:
            st.warning("âš ï¸ æœªè¨­å®š Drive è³‡æ–™å¤¾ ID")

except Exception as e:
    st.error("âŒ ç³»çµ±ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼Œè«‹é€šçŸ¥ç®¡ç†å“¡ã€‚")
    print(traceback.format_exc())  
